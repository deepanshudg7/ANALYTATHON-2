{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytathon 2 - Bird Song Recognization\n",
    "Acoustic recordings of bird songs can be used to monitor bird species in a region. It is difficult for experts to analyse the presence of specific bird species by listening to these recordings. You will address this challenge by developing computational tools to automatically classify and \n",
    "cluster bird songs to detect the presence of various species in the wild based on their recordings. Bird song recordings were sourced from the citizen science website xeno_canto, which provides audio files of bird songs from around the world. \n",
    "\n",
    "## Goal 1: Build a model to classify the bird audio clips\n",
    "\n",
    "### Q1: How will you split the data into test and training sets?\n",
    "### Q2: What is the most appropriate model for the problem?\n",
    "### Q3: What level of performance is good enough to be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import  DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "\n",
    "torch.manual_seed(99)\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the images\n",
    "greypatridgespec = 'D:/college/8023/Analytathon 2/code/Goal1/greypartridgespec'\n",
    "stockdovespec= 'D:/college/8023/Analytathon 2/code/Goal1/stockdovespec'\n",
    "turtledovespec='D:/college/8023/Analytathon 2/code/Goal1/turtledovespec'\n",
    "yellowhammerspec='D:/college/8023/Analytathon 2/code/Goal1/yellowhammerspec'\n",
    "\n",
    "# List of all image file names in the directory\n",
    "img_files_grey = os.listdir(greypatridgespec)\n",
    "img_files_stock = os.listdir(stockdovespec)\n",
    "img_files_turtle = os.listdir(turtledovespec)\n",
    "img_files_yellow = os.listdir(yellowhammerspec)\n",
    "\n",
    "classes=['greypatridgespec','stockdovespec','turtledovespec','yellowhammerspeck']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image resizer function\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def imageResizer(img):\n",
    "    # target_height = 128\n",
    "    # target_width = 216\n",
    "    # width, height = img.size\n",
    "\n",
    "    # if width > height:\n",
    "    #     new_width = target_width\n",
    "    #     new_height = int(height * (target_width / width))\n",
    "    # else:\n",
    "    #     new_width = int(width * (target_height / height))\n",
    "    #     new_height = target_height\n",
    "\n",
    "    # img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "    # new_img = Image.new('L', (target_width, target_height),0)\n",
    "    \n",
    "    # left = int((target_width - new_width) / 2)\n",
    "    # top = int((target_height - new_height) / 2)\n",
    "    # new_img.paste(img, (left, top))\n",
    "    new_img =cv2.resize(img,(128,128))\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image reader function\n",
    "\n",
    "def imageReader(image_list,file_path,label_name):\n",
    "    data=[]\n",
    "    for i,file_name in enumerate(image_list):\n",
    "    # Load the image\n",
    "\n",
    "        img_path = os.path.join(file_path, file_name)\n",
    "       # img = Image.open(img_path)\n",
    "        img=cv2.imread(img_path,0)\n",
    "\n",
    "    # image resizer\n",
    "        img=imageResizer(img)\n",
    "    \n",
    "    # Converting to numpy array \n",
    "\n",
    "        img_arr = np.array(img, dtype=np.float32)\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "        img_arr = img_arr / 255.0\n",
    "    \n",
    "    \n",
    "\n",
    "        data.append({'image':img_arr,'label':f'{label_name}'})\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images\n",
    "\n",
    "\n",
    "df_filtered_grey=imageReader(img_files_grey,greypatridgespec,'greypatridgespec')\n",
    "df_filtered_stock=imageReader(img_files_stock,stockdovespec,'stockdovespec')\n",
    "df_filtered_turtle = imageReader(img_files_turtle,turtledovespec,'turtledovespec')\n",
    "df_filtered_yellow= imageReader(img_files_yellow,yellowhammerspec,'yellowhammerspec')\n",
    "\n",
    "print(df_filtered_grey.shape,df_filtered_stock.shape,df_filtered_turtle.shape,df_filtered_yellow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_birds = pd.concat([df_filtered_grey,df_filtered_stock,df_filtered_turtle,df_filtered_yellow],ignore_index=True)\n",
    "df_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_birds.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: How will you split the data into test and training sets?\n",
    "\n",
    "The data was observed and found that all the images were not of the same dimension, So we found out the most common dimension and resized all the images to the same dimension. As the sample is representative , we have 1000 samples from each species. Further , we split the dataset into training and test dataset with 80/20 ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,test_images,train_labels,test_labels=train_test_split(df_birds.image,df_birds.label,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=np.stack(train_images.values).astype('float32')\n",
    "test_images=np.stack(test_images.values).astype('float32')\n",
    "\n",
    "train_data=torch.tensor(train_images)\n",
    "test_data=torch.tensor(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_reshaped = train_data.reshape(-1,1,128,128)\n",
    "test_images_reshaped = test_data.reshape(-1,1,128,128)\n",
    "test_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels_encoded = encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = encoder.transform(test_labels)\n",
    "\n",
    "\n",
    "train_label_data= torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "test_label_data= torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "print(len(train_label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axs = plt.subplots(4,4,figsize=(8,8))\n",
    "axs = axs.flatten()\n",
    "for n,ax in enumerate(axs):\n",
    "    ax.imshow(test_data[n],cmap=\"Greys\")\n",
    "    ax.set_title(classes[test_label_data[n]],fontsize=8)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_label_data.size(),train_images_reshaped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =TensorDataset(train_label_data,train_images_reshaped)\n",
    "test_dataset =TensorDataset(test_label_data,test_images_reshaped)\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2:  What is the most appropriate model for the problem??\n",
    "\n",
    "The most appropriate model for the problem is a CNN where we could work over image data. The model used in this problem contains of 3 Convolutional layers and 1 fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4)\n",
    "            \n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16384, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(200, 4),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            # nn.LeakyReLU(True),\n",
    "            # nn.Linear(128, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = self.cnn(x)\n",
    "        out= self.fc(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "# cnn= CNN()\n",
    "\n",
    "# x= torch.randn(4,1,128,128)\n",
    "# y=cnn(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "n_pixels = 128*216\n",
    "num_classes = 4\n",
    "\n",
    "def train(model,train_loader,test_loader,num_epochs,optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epochs, epoch_loss, epoch_val_loss, epoch_accuracy= [],[],[],[]\n",
    "    for n in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx,(labels, data) in enumerate(train_loader):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(data.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "        train_loss = train_loss/(batch_idx+1)\n",
    "        epoch_loss.append(train_loss)\n",
    "        model.eval()  \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx,(labels, data) in enumerate(test_loader):\n",
    "                outputs = model(data.float())\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_list.append(loss)\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                total += len(labels)\n",
    "                \n",
    "        val_loss = np.mean(loss_list)\n",
    "        epoch_val_loss.append(val_loss)\n",
    "        accuracy = correct/total  \n",
    "        epoch_accuracy.append(accuracy*100)\n",
    "        epochs.append(n+1)\n",
    "        print(f'{n+1} / {num_epochs}: loss {train_loss:0.03f}, test_loss {val_loss:0.03f}, accuracy {accuracy:0.03f}')\n",
    "        \n",
    "    fig,axs = plt.subplots(1,2,figsize=(16,5))\n",
    "    axs[0].plot(epochs,epoch_loss,label='train')\n",
    "    axs[0].plot(epochs,epoch_val_loss,label='test')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[1].plot(epochs,epoch_accuracy)\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data,loss_fn):\n",
    "    size = len(test_data.dataset)\n",
    "    num_batches = len(test_data)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    label_array = np.zeros(len(test_dataset))\n",
    "    pred_array = np.zeros(len(test_dataset))\n",
    "    n=0\n",
    "    with torch.no_grad():\n",
    "        for labels,images in test_data:\n",
    "            pred = model(images.float())\n",
    "            pred_labels = pred.argmax(1)\n",
    "            test_loss += loss_fn(pred, labels).item()\n",
    "            correct += (pred_labels == labels).sum().item()\n",
    "\n",
    "            for label, prediction in zip(labels, pred_labels):\n",
    "                \n",
    "                label_array[n] = label\n",
    "                pred_array[n] = prediction\n",
    "                n=n+1\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return label_array, pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "train(model,train_loader,test_loader,15,optimizer)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: What level of performance is good enough to be useful?\n",
    "\n",
    "Training the model for 100 epoch we could see that the training and test loss were steadily decreasing. The training loss is decreasing with every epoche and has not saturated suggesting some underfitting. We also observe the test loss is slightly worse than the train loss, which suggest overfitting. Measures have been put in place to reduce over fitting seem to work as the difference is not very large ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param = 0\n",
    "for parameter in model.parameters():\n",
    "    n_param+=np.prod(parameter.shape)\n",
    "n_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enumerator = enumerate(test_loader)\n",
    "batch_idx, (labels,images) = next(test_enumerator)\n",
    "# batch_idx, (images, labels) = next(test_enumerator)\n",
    "print(images.shape)\n",
    "\n",
    "pred_labels = model(images).argmax(1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "for n, ax in enumerate(axs):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images[n][0], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(classes[pred_labels[n]] + '/' + classes[labels[n]],fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "label_array, pred_array = test(model,test_loader,loss_fn)\n",
    "\n",
    "from sklearn import metrics\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(label_array, pred_array,\n",
    "                display_labels=classes,\n",
    "                normalize='true')\n",
    "fig = plt.gcf()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix and average accuracy suggest we have around 82 % accuracy which seems to be good enough for the model to work as we look over the fit of the curve generated for train and test losses."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
